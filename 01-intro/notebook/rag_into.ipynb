{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm.auto  import tqdm\n",
    "\n",
    "\n",
    "from elasticsearch import Elasticsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'e359b3f82038', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'LuNImNV6RB2lHk25Z9NgRA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "es_client.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"how do I run kafka?\"\n",
    "\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": q,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the question based on the context from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the Question.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_result(query):\n",
    "\n",
    "    with open('documents.json','rt') as f_in:\n",
    "        docs_raw = json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "\n",
    "    for course_dict in docs_raw:\n",
    "        for doc in course_dict['documents']:\n",
    "            doc['course'] = course_dict['course']\n",
    "            documents.append(doc)\n",
    "            \n",
    "\n",
    "    index = minsearch.Index(\n",
    "        text_fields=[\"question\",\"text\",\"section\"],\n",
    "        keyword_fields=['course']\n",
    "        )\n",
    "\n",
    "    index.fit(documents)\n",
    "\n",
    "\n",
    "\n",
    "    boost = { 'question':3.0,'section':0.5}\n",
    "\n",
    "    search_results = index.search(\n",
    "            query=query,\n",
    "            filter_dict={'course':'data-engineering-zoomcamp'},\n",
    "            boost_dict=boost,\n",
    "            num_results=5\n",
    "        )\n",
    "    \n",
    "    return search_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_result(query):\n",
    "\n",
    "    index_name = \"course-questions\"\n",
    "\n",
    "    try:\n",
    "       es_client.indices.create(index=index_name,body=index_settings)\n",
    "    except:\n",
    "       pass\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    with open('documents.json','rt') as f_in:\n",
    "        docs_raw = json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "\n",
    "    for course_dict in docs_raw:\n",
    "        for doc in course_dict['documents']:\n",
    "            doc['course'] = course_dict['course']\n",
    "            documents.append(doc)\n",
    "\n",
    "    for doc in tqdm(documents):\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "\n",
    "    response = es_client.search(index=index_name,body=query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_prompt(context,question,prompt_template):\n",
    "\n",
    "\n",
    "    prompt = prompt_template.format(question=question,context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_result(prompt):\n",
    "    response = client.chat.completions.create(model='gpt-4o',messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "    results = response.choices[0].message.content\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query,prompt_template,search_engine=None):\n",
    "    if search_engine == \"minsearch\":\n",
    "       search_results = minsearch_result(query)\n",
    "    else:\n",
    "       search_results = elastic_search_result(query)\n",
    "\n",
    "    context = create_context(search_results)\n",
    "    prompt = create_prompt(context=context,question=query,prompt_template=prompt_template)\n",
    "    print(prompt)\n",
    "    \n",
    "    return get_query_result(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the question based on the context from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the Question.\n",
      "\n",
      "QUESTION:  how do I run kafka?\n",
      "\n",
      "CONTEXT: section: Module 6: streaming with kafka\n",
      "question: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
      "answer: In the project directory, run:\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Python Kafka: ./build.sh: Permission denied Error\n",
      "answer: Run this command in terminal in the same directory (/docker/spark):\n",
      "chmod +x build.sh\n",
      "\n",
      "section: Project\n",
      "question: How to fix the error \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\"?\n",
      "answer: According to https://github.com/dpkp/kafka-python/\n",
      "“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\n",
      "Use pip install kafka-python-ng instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To run Kafka, follow these instructions depending on whether you want to run a Java or Python Kafka application:\\n\\n### For Java Kafka:\\nIn the project directory, you can run the following command:\\n```sh\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\nReplace `<jar_name>` with the actual name of your JAR file.\\n\\n### For Python Kafka:\\n1. **Create and activate a virtual environment** (only needed once):\\n   ```sh\\n   python -m venv env\\n   source env/bin/activate  # For MacOS/Linux\\n   env/Scripts/activate  # For Windows\\n   ```\\n\\n2. **Install the necessary packages** using `requirements.txt`:\\n   ```sh\\n   pip install -r ../requirements.txt\\n   ```\\n\\n3. **Activate the virtual environment** whenever needed:\\n   ```sh\\n   source env/bin/activate  # For MacOS/Linux\\n   env/Scripts/activate  # For Windows\\n   ```\\n\\n4. **Deactivate the virtual environment** after you are done:\\n   ```sh\\n   deactivate\\n   ```\\n\\nEnsure all Docker images are up and running before you execute the Python files.\\n\\n#### Additional Notes:\\nIf you encounter a `Permission denied` error when running `build.sh`, you can fix it by running the following command in the same directory:\\n```sh\\nchmod +x build.sh\\n```'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(q,prompt_template,\"minsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:01<00:00, 658.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the question based on the context from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the Question.\n",
      "\n",
      "QUESTION: {'size': 5, 'query': {'bool': {'must': {'multi_match': {'query': 'how do I run kafka?', 'fields': ['question^3', 'text', 'section'], 'type': 'best_fields'}}, 'filter': {'term': {'course': 'data-engineering-zoomcamp'}}}}}\n",
      "\n",
      "CONTEXT: section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
      "answer: In the project directory, run:\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
      "answer: In the project directory, run:\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the context of the Data Engineering Zoomcamp, here is how you can run Kafka:\\n\\nFor Java-based Kafka, to run producer/consumer/kstreams/etc in the terminal, navigate to your project directory and execute the following command:\\n\\n```bash\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\\n```\\n\\nMake sure to replace `<jar_name>` with the actual name of your jar file.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(search_query,prompt_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
