{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto  import tqdm\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "from elasticsearch import Elasticsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "es_client.info()\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama')\n",
    "\n",
    "\n",
    "ollama.pull('phi3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"how do I run kafka?\"\n",
    "\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": q,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the question based on the context from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the Question.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_result(query):\n",
    "\n",
    "    with open('../../data/documents.json','rt') as f_in:\n",
    "        docs_raw = json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "\n",
    "    for course_dict in docs_raw:\n",
    "        for doc in course_dict['documents']:\n",
    "            doc['course'] = course_dict['course']\n",
    "            documents.append(doc)\n",
    "            \n",
    "\n",
    "    index = minsearch.Index(\n",
    "        text_fields=[\"question\",\"text\",\"section\"],\n",
    "        keyword_fields=['course']\n",
    "        )\n",
    "\n",
    "    index.fit(documents)\n",
    "\n",
    "\n",
    "\n",
    "    boost = { 'question':3.0,'section':0.5}\n",
    "\n",
    "    search_results = index.search(\n",
    "            query=query,\n",
    "            filter_dict={'course':'data-engineering-zoomcamp'},\n",
    "            boost_dict=boost,\n",
    "            num_results=5\n",
    "        )\n",
    "    \n",
    "    return search_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_result(query):\n",
    "\n",
    "    index_name = \"course-questions\"\n",
    "\n",
    "    try:\n",
    "       es_client.indices.create(index=index_name,body=index_settings)\n",
    "    except:\n",
    "       pass\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    with open('../../data/documents.json','rt') as f_in:\n",
    "        docs_raw = json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "\n",
    "    for course_dict in docs_raw:\n",
    "        for doc in course_dict['documents']:\n",
    "            doc['course'] = course_dict['course']\n",
    "            documents.append(doc)\n",
    "\n",
    "    for doc in tqdm(documents):\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "\n",
    "    response = es_client.search(index=index_name,body=query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  create_prompt(context,question,prompt_template):\n",
    "\n",
    "\n",
    "    prompt = prompt_template.format(question=question,context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_result(prompt):\n",
    "    response = client.chat.completions.create(model='phi3',messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "    results = response.choices[0].message.content\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query,prompt_template,search_engine=None):\n",
    "    if search_engine == \"minsearch\":\n",
    "       search_results = minsearch_result(query)\n",
    "    else:\n",
    "       search_results = elastic_search_result(query)\n",
    "\n",
    "    context = create_context(search_results)\n",
    "    prompt = create_prompt(context=context,question=query,prompt_template=prompt_template)\n",
    "    print(prompt)\n",
    "    \n",
    "    return get_query_result(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the question based on the context from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the Question.\n",
      "\n",
      "QUESTION: how do I run kafka?\n",
      "\n",
      "CONTEXT: section: Module 6: streaming with kafka\n",
      "question: Java Kafka: How to run producer/consumer/kstreams/etc in terminal\n",
      "answer: In the project directory, run:\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Python Kafka: ./build.sh: Permission denied Error\n",
      "answer: Run this command in terminal in the same directory (/docker/spark):\n",
      "chmod +x build.sh\n",
      "\n",
      "section: Project\n",
      "question: How to fix the error \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\"?\n",
      "answer: According to https://github.com/dpkp/kafka-python/\n",
      "“DUE TO ISSUES WITH RELEASES, IT IS SUGGESTED TO USE https://github.com/wbarnha/kafka-python-ng FOR THE TIME BEING”\n",
      "Use pip install kafka-python-ng instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" To run Kafka in Python with a virtual environment on MacOS or Linux:\\n1. Create a new directory for your project, then navigate into it using the `cd` command: \\n```bash\\nmkdir my_kafka_project\\ncd my_kafka_project\\n```\\n2. Inside this directory, create and activate a Python virtual environment with these commands (run only once): \\n```bash\\npython -m venv env\\nsource env/bin/activate\\n```\\n3. Install necessary packages in the active environment using pip:\\n```bash\\npip install kafka-python requests pika Pillow psutil six PyYAML arrow sqlalch0me future # This list can grow as your project grows, but this is a good start \\n```\\n4. To run producer or consumer scripts for Kafka in Python within the virtual environment activate it first and execute with `python`:  \\n```bash\\nsource env/bin/activate\\npython my_project/producer.py # Replace 'producer.py' with your actual script name \\ndeactivate\\n```\\nPlease note that this is a simplistic approach for running Kafka-related tasks and the FAQs do not cover setting up Zookeeper or configuring security mechanisms on Apache Kafka, which may be important depending upon real-world use cases. Also remember to replace `my_project/producer.py` with your actual script filename if different in context of this example project structure.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(q,prompt_template,\"minsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:01<00:00, 766.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the question based on the context from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the Question.\n",
      "\n",
      "QUESTION: {'size': 5, 'query': {'bool': {'must': {'multi_match': {'query': 'how do I run kafka?', 'fields': ['question^3', 'text', 'section'], 'type': 'best_fields'}}, 'filter': {'term': {'course': 'data-engineering-zoomcamp'}}}}}\n",
      "\n",
      "CONTEXT: section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n",
      "\n",
      "section: Workshop 1 - dlthub\n",
      "question: How do I install the necessary dependencies to run the code?\n",
      "answer: Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Answer: To run the code for Workshop 1 - dlthub on ZoomCamp, first make sure that 'dlt[duckdb]' and DuckDB are both installed. Execute !pip install dlt[duckdb] to get started with installing these packages in your environment (ZoomCamp). Additionally, ensure you have pip itself installed before adding the duckdb package as well since it is also a requirement for running this code successfully on ZoomCamp's platform.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(search_query,prompt_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
